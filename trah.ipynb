{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from textblob import TextBlob\n",
    "# from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>this paper was a continuation of \\cite{cxy}. l...</td>\n",
       "      <td>, Mathematics, Representation Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>machine learning was essentially a sciences of...</td>\n",
       "      <td>, Computer Science, Statistics, Artificial Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>an explorative data analysis system should be ...</td>\n",
       "      <td>, Statistics, Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>we analyze a optical counterpart to a ultra-co...</td>\n",
       "      <td>, Physics, Astrophysics of Galaxies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>the fundamental issue concerning iron-based su...</td>\n",
       "      <td>, Physics, Materials Science, Strongly Correla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ABSTRACT  \\\n",
       "9995  this paper was a continuation of \\cite{cxy}. l...   \n",
       "9996  machine learning was essentially a sciences of...   \n",
       "9997  an explorative data analysis system should be ...   \n",
       "9998  we analyze a optical counterpart to a ultra-co...   \n",
       "9999  the fundamental issue concerning iron-based su...   \n",
       "\n",
       "                                               category  \n",
       "9995               , Mathematics, Representation Theory  \n",
       "9996  , Computer Science, Statistics, Artificial Int...  \n",
       "9997                     , Statistics, Machine Learning  \n",
       "9998                , Physics, Astrophysics of Galaxies  \n",
       "9999  , Physics, Materials Science, Strongly Correla...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=pd.read_csv('train.csv')\n",
    "df=df_train.copy()\n",
    "df_test=pd.read_csv('test.csv')\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ABSTRACT  10000 non-null  object\n",
      " 1   category  10000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all the categories in the training data\n",
    "cat=[s.split(',') for s in df.category]\n",
    "cat_set={ s[i]  for s in cat for i in (range(len(s)))}\n",
    "len(cat_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a first round of text cleaning techniques\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a backpressure algorithm has been widely used ...</td>\n",
       "      <td>, Computer Science, Mathematics, Optimization ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inside this paper we present an exactly solvab...</td>\n",
       "      <td>, Physics, Strongly Correlated Electrons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a present numerical study aims at shedding lig...</td>\n",
       "      <td>, Physics, Fluid Dynamics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with the help of angleresolved photoemission s...</td>\n",
       "      <td>, Physics, Strongly Correlated Electrons, Supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>based on subarcsecond atacama large millimeter...</td>\n",
       "      <td>, Physics, Astrophysics of Galaxies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>this paper was a continuation of citecxy let b...</td>\n",
       "      <td>, Mathematics, Representation Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>machine learning was essentially a sciences of...</td>\n",
       "      <td>, Computer Science, Statistics, Artificial Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>an explorative data analysis system should be ...</td>\n",
       "      <td>, Statistics, Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>we analyze a optical counterpart to a ultracom...</td>\n",
       "      <td>, Physics, Astrophysics of Galaxies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>the fundamental issue concerning ironbased sup...</td>\n",
       "      <td>, Physics, Materials Science, Strongly Correla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ABSTRACT  \\\n",
       "0     a backpressure algorithm has been widely used ...   \n",
       "1     inside this paper we present an exactly solvab...   \n",
       "2     a present numerical study aims at shedding lig...   \n",
       "3     with the help of angleresolved photoemission s...   \n",
       "4     based on subarcsecond atacama large millimeter...   \n",
       "...                                                 ...   \n",
       "9995  this paper was a continuation of citecxy let b...   \n",
       "9996  machine learning was essentially a sciences of...   \n",
       "9997  an explorative data analysis system should be ...   \n",
       "9998  we analyze a optical counterpart to a ultracom...   \n",
       "9999  the fundamental issue concerning ironbased sup...   \n",
       "\n",
       "                                               category  \n",
       "0     , Computer Science, Mathematics, Optimization ...  \n",
       "1              , Physics, Strongly Correlated Electrons  \n",
       "2                             , Physics, Fluid Dynamics  \n",
       "3     , Physics, Strongly Correlated Electrons, Supe...  \n",
       "4                   , Physics, Astrophysics of Galaxies  \n",
       "...                                                 ...  \n",
       "9995               , Mathematics, Representation Theory  \n",
       "9996  , Computer Science, Statistics, Artificial Int...  \n",
       "9997                     , Statistics, Machine Learning  \n",
       "9998                , Physics, Astrophysics of Galaxies  \n",
       "9999  , Physics, Materials Science, Strongly Correla...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[\"ABSTRACT\"]=df.ABSTRACT.apply(round1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Analysis of PDEs', 'Applications', 'Artificial Intelligence',\n",
       "       'Astrophysics of Galaxies', 'Computation and Language',\n",
       "       'Computer Science', 'Computer Vision and Pattern Recognition',\n",
       "       'Cosmology and Nongalactic Astrophysics',\n",
       "       'Data Structures and Algorithms', 'Differential Geometry',\n",
       "       'Earth and Planetary Astrophysics', 'Fluid Dynamics',\n",
       "       'Information Theory', 'Instrumentation and Methods for Astrophysics',\n",
       "       'Machine Learning', 'Materials Science', 'Mathematics', 'Methodology',\n",
       "       'Number Theory', 'Optimization and Control', 'Physics',\n",
       "       'Representation Theory', 'Robotics', 'Social and Information Networks',\n",
       "       'Statistics', 'Statistics Theory', 'Strongly Correlated Electrons',\n",
       "       'Superconductivity', 'Systems and Control'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exemple=pd.read_csv('SampleSubmission.csv')\n",
    "categories=exemple.columns[1:]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a second round of cleaning\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a backpressure algorithm has been widely used ...</td>\n",
       "      <td>, Computer Science, Mathematics, Optimization ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inside this paper we present an exactly solvab...</td>\n",
       "      <td>, Physics, Strongly Correlated Electrons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a present numerical study aims at shedding lig...</td>\n",
       "      <td>, Physics, Fluid Dynamics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with the help of angleresolved photoemission s...</td>\n",
       "      <td>, Physics, Strongly Correlated Electrons, Supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>based on subarcsecond atacama large millimeter...</td>\n",
       "      <td>, Physics, Astrophysics of Galaxies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>this paper was a continuation of citecxy let b...</td>\n",
       "      <td>, Mathematics, Representation Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>machine learning was essentially a sciences of...</td>\n",
       "      <td>, Computer Science, Statistics, Artificial Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>an explorative data analysis system should be ...</td>\n",
       "      <td>, Statistics, Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>we analyze a optical counterpart to a ultracom...</td>\n",
       "      <td>, Physics, Astrophysics of Galaxies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>the fundamental issue concerning ironbased sup...</td>\n",
       "      <td>, Physics, Materials Science, Strongly Correla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ABSTRACT  \\\n",
       "0     a backpressure algorithm has been widely used ...   \n",
       "1     inside this paper we present an exactly solvab...   \n",
       "2     a present numerical study aims at shedding lig...   \n",
       "3     with the help of angleresolved photoemission s...   \n",
       "4     based on subarcsecond atacama large millimeter...   \n",
       "...                                                 ...   \n",
       "9995  this paper was a continuation of citecxy let b...   \n",
       "9996  machine learning was essentially a sciences of...   \n",
       "9997  an explorative data analysis system should be ...   \n",
       "9998  we analyze a optical counterpart to a ultracom...   \n",
       "9999  the fundamental issue concerning ironbased sup...   \n",
       "\n",
       "                                               category  \n",
       "0     , Computer Science, Mathematics, Optimization ...  \n",
       "1              , Physics, Strongly Correlated Electrons  \n",
       "2                             , Physics, Fluid Dynamics  \n",
       "3     , Physics, Strongly Correlated Electrons, Supe...  \n",
       "4                   , Physics, Astrophysics of Galaxies  \n",
       "...                                                 ...  \n",
       "9995               , Mathematics, Representation Theory  \n",
       "9996  , Computer Science, Statistics, Artificial Int...  \n",
       "9997                     , Statistics, Machine Learning  \n",
       "9998                , Physics, Astrophysics of Galaxies  \n",
       "9999  , Physics, Materials Science, Strongly Correla...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ABSTRACT\"]=df.ABSTRACT.apply(round2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x46559 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 684410 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(df.ABSTRACT)\n",
    "data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['category']=df['category'].apply(lambda s : s.split(',')[1:])\n",
    "# one_hot_encoded = pd.get_dummies(df['category'].apply(pd.Series).stack()).sum(level=0)\n",
    "# df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a backpressure algorithm has been widely used ...</td>\n",
       "      <td>, Computer Science, Mathematics, Optimization ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inside this paper we present an exactly solvab...</td>\n",
       "      <td>, Physics, Strongly Correlated Electrons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a present numerical study aims at shedding lig...</td>\n",
       "      <td>, Physics, Fluid Dynamics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with the help of angleresolved photoemission s...</td>\n",
       "      <td>, Physics, Strongly Correlated Electrons, Supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>based on subarcsecond atacama large millimeter...</td>\n",
       "      <td>, Physics, Astrophysics of Galaxies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ABSTRACT  \\\n",
       "0  a backpressure algorithm has been widely used ...   \n",
       "1  inside this paper we present an exactly solvab...   \n",
       "2  a present numerical study aims at shedding lig...   \n",
       "3  with the help of angleresolved photoemission s...   \n",
       "4  based on subarcsecond atacama large millimeter...   \n",
       "\n",
       "                                            category  \n",
       "0  , Computer Science, Mathematics, Optimization ...  \n",
       "1           , Physics, Strongly Correlated Electrons  \n",
       "2                          , Physics, Fluid Dynamics  \n",
       "3  , Physics, Strongly Correlated Electrons, Supe...  \n",
       "4                , Physics, Astrophysics of Galaxies  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize\n",
    "import  nltk\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return ' '.join(tokens) \n",
    "\n",
    "df['ABSTRACT']=df['ABSTRACT'].apply(tokenize_text)\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yalla tarf eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9995    thi paper wa a continu of citecxi let bf g be ...\n",
       "9996    machin learn wa essenti a scienc of play with ...\n",
       "9997    an explor data analysi system should be awar o...\n",
       "9998    we analyz a optic counterpart to a ultracompac...\n",
       "9999    the fundament issu concern ironbas superconduc...\n",
       "Name: ABSTRACT, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps=nltk.PorterStemmer()\n",
    "df[\"ABSTRACT\"]=df[\"ABSTRACT\"].apply(lambda content: ' '.join([ps.stem(word) for word in content.split(' ')]))\n",
    "df[\"ABSTRACT\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 1, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "df.drop('category', axis=1)\n",
    "\n",
    "x=df[\"ABSTRACT\"]\n",
    "y=df['category']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Create an instance of the MultiLabelBinarizer transformer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit the transformer on the target variable y_train\n",
    "mlb.fit(y_train)\n",
    "\n",
    "# Transform y_train and y_test to binary arrays\n",
    "\n",
    "\n",
    "y_train_bin = mlb.transform(y_train)\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "clf = LogisticRegression()\n",
    "y_train_bin\n",
    "\n",
    "clf.fit(X_train_tfidf, y_train_bin)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# # Use the trained model to make predictions on the test data\n",
    "# y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# # Evaluate the performance of the model on the test data\n",
    "# accuracy = accuracy_score(y_test_bin, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# cv = CountVectorizer()\n",
    "# bow1=cv.fit_transform(X_train)\n",
    "# bow1_test=cv.transform(X_test)\n",
    "# tfidf = TfidfVectorizer()\n",
    "# bow2=tfidf.fit_transform(X_train)\n",
    "# bow2_test=tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation accuracy from  MultinomialNB()  :  nan\n",
      "-----------------------------------------------------------\n",
      "cross validation accuracy from  LogisticRegression(max_iter=1000)  :  nan\n",
      "-----------------------------------------------------------\n",
      "cross validation accuracy from  SVC()  :  nan\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 663, in fit\n",
      "    X, y = self._check_X_y(X, y)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 523, in _check_X_y\n",
      "    return self._validate_data(X, y, accept_sparse=\"csr\", reset=reset)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (8000, 29) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1508, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (8000, 29) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 190, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"c:\\Users\\salma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (8000, 29) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.svm import SVC\n",
    "# tfidf = TfidfVectorizer()\n",
    "# bow=tfidf.fit_transform(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
