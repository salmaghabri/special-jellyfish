{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>this paper was a continuation of \\cite{cxy}. l...</td>\n",
       "      <td>, Mathematics, Representation Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>machine learning was essentially a sciences of...</td>\n",
       "      <td>, Computer Science, Statistics, Artificial Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>an explorative data analysis system should be ...</td>\n",
       "      <td>, Statistics, Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>we analyze a optical counterpart to a ultra-co...</td>\n",
       "      <td>, Physics, Astrophysics of Galaxies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>the fundamental issue concerning iron-based su...</td>\n",
       "      <td>, Physics, Materials Science, Strongly Correla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ABSTRACT  \\\n",
       "9995  this paper was a continuation of \\cite{cxy}. l...   \n",
       "9996  machine learning was essentially a sciences of...   \n",
       "9997  an explorative data analysis system should be ...   \n",
       "9998  we analyze a optical counterpart to a ultra-co...   \n",
       "9999  the fundamental issue concerning iron-based su...   \n",
       "\n",
       "                                               category  \n",
       "9995               , Mathematics, Representation Theory  \n",
       "9996  , Computer Science, Statistics, Artificial Int...  \n",
       "9997                     , Statistics, Machine Learning  \n",
       "9998                , Physics, Astrophysics of Galaxies  \n",
       "9999  , Physics, Materials Science, Strongly Correla...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=pd.read_csv('train.csv')\n",
    "df=df_train.copy()\n",
    "df_test=pd.read_csv('test.csv')\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ABSTRACT  10000 non-null  object\n",
      " 1   category  10000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all the categories in the training data\n",
    "cat=[s.split(',') for s in df.category]\n",
    "cat_set={ s[i]  for s in cat for i in (range(len(s)))}\n",
    "len(cat_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a first round of text cleaning techniques\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a backpressure algorithm has been widely used ...</td>\n",
       "      <td>, Computer Science, Mathematics, Optimization ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inside this paper we present an exactly solvab...</td>\n",
       "      <td>, Physics, Strongly Correlated Electrons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a present numerical study aims at shedding lig...</td>\n",
       "      <td>, Physics, Fluid Dynamics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with the help of angleresolved photoemission s...</td>\n",
       "      <td>, Physics, Strongly Correlated Electrons, Supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>based on subarcsecond atacama large millimeter...</td>\n",
       "      <td>, Physics, Astrophysics of Galaxies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>this paper was a continuation of citecxy let b...</td>\n",
       "      <td>, Mathematics, Representation Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>machine learning was essentially a sciences of...</td>\n",
       "      <td>, Computer Science, Statistics, Artificial Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>an explorative data analysis system should be ...</td>\n",
       "      <td>, Statistics, Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>we analyze a optical counterpart to a ultracom...</td>\n",
       "      <td>, Physics, Astrophysics of Galaxies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>the fundamental issue concerning ironbased sup...</td>\n",
       "      <td>, Physics, Materials Science, Strongly Correla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ABSTRACT  \\\n",
       "0     a backpressure algorithm has been widely used ...   \n",
       "1     inside this paper we present an exactly solvab...   \n",
       "2     a present numerical study aims at shedding lig...   \n",
       "3     with the help of angleresolved photoemission s...   \n",
       "4     based on subarcsecond atacama large millimeter...   \n",
       "...                                                 ...   \n",
       "9995  this paper was a continuation of citecxy let b...   \n",
       "9996  machine learning was essentially a sciences of...   \n",
       "9997  an explorative data analysis system should be ...   \n",
       "9998  we analyze a optical counterpart to a ultracom...   \n",
       "9999  the fundamental issue concerning ironbased sup...   \n",
       "\n",
       "                                               category  \n",
       "0     , Computer Science, Mathematics, Optimization ...  \n",
       "1              , Physics, Strongly Correlated Electrons  \n",
       "2                             , Physics, Fluid Dynamics  \n",
       "3     , Physics, Strongly Correlated Electrons, Supe...  \n",
       "4                   , Physics, Astrophysics of Galaxies  \n",
       "...                                                 ...  \n",
       "9995               , Mathematics, Representation Theory  \n",
       "9996  , Computer Science, Statistics, Artificial Int...  \n",
       "9997                     , Statistics, Machine Learning  \n",
       "9998                , Physics, Astrophysics of Galaxies  \n",
       "9999  , Physics, Materials Science, Strongly Correla...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[\"ABSTRACT\"]=df.ABSTRACT.apply(round1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Analysis of PDEs', 'Applications', 'Artificial Intelligence',\n",
       "       'Astrophysics of Galaxies', 'Computation and Language',\n",
       "       'Computer Science', 'Computer Vision and Pattern Recognition',\n",
       "       'Cosmology and Nongalactic Astrophysics',\n",
       "       'Data Structures and Algorithms', 'Differential Geometry',\n",
       "       'Earth and Planetary Astrophysics', 'Fluid Dynamics',\n",
       "       'Information Theory', 'Instrumentation and Methods for Astrophysics',\n",
       "       'Machine Learning', 'Materials Science', 'Mathematics', 'Methodology',\n",
       "       'Number Theory', 'Optimization and Control', 'Physics',\n",
       "       'Representation Theory', 'Robotics', 'Social and Information Networks',\n",
       "       'Statistics', 'Statistics Theory', 'Strongly Correlated Electrons',\n",
       "       'Superconductivity', 'Systems and Control'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exemple=pd.read_csv('SampleSubmission.csv')\n",
    "categories=exemple.columns[1:]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a second round of cleaning\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a backpressure algorithm has been widely used ...</td>\n",
       "      <td>, Computer Science, Mathematics, Optimization ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inside this paper we present an exactly solvab...</td>\n",
       "      <td>, Physics, Strongly Correlated Electrons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a present numerical study aims at shedding lig...</td>\n",
       "      <td>, Physics, Fluid Dynamics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with the help of angleresolved photoemission s...</td>\n",
       "      <td>, Physics, Strongly Correlated Electrons, Supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>based on subarcsecond atacama large millimeter...</td>\n",
       "      <td>, Physics, Astrophysics of Galaxies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>this paper was a continuation of citecxy let b...</td>\n",
       "      <td>, Mathematics, Representation Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>machine learning was essentially a sciences of...</td>\n",
       "      <td>, Computer Science, Statistics, Artificial Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>an explorative data analysis system should be ...</td>\n",
       "      <td>, Statistics, Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>we analyze a optical counterpart to a ultracom...</td>\n",
       "      <td>, Physics, Astrophysics of Galaxies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>the fundamental issue concerning ironbased sup...</td>\n",
       "      <td>, Physics, Materials Science, Strongly Correla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ABSTRACT  \\\n",
       "0     a backpressure algorithm has been widely used ...   \n",
       "1     inside this paper we present an exactly solvab...   \n",
       "2     a present numerical study aims at shedding lig...   \n",
       "3     with the help of angleresolved photoemission s...   \n",
       "4     based on subarcsecond atacama large millimeter...   \n",
       "...                                                 ...   \n",
       "9995  this paper was a continuation of citecxy let b...   \n",
       "9996  machine learning was essentially a sciences of...   \n",
       "9997  an explorative data analysis system should be ...   \n",
       "9998  we analyze a optical counterpart to a ultracom...   \n",
       "9999  the fundamental issue concerning ironbased sup...   \n",
       "\n",
       "                                               category  \n",
       "0     , Computer Science, Mathematics, Optimization ...  \n",
       "1              , Physics, Strongly Correlated Electrons  \n",
       "2                             , Physics, Fluid Dynamics  \n",
       "3     , Physics, Strongly Correlated Electrons, Supe...  \n",
       "4                   , Physics, Astrophysics of Galaxies  \n",
       "...                                                 ...  \n",
       "9995               , Mathematics, Representation Theory  \n",
       "9996  , Computer Science, Statistics, Artificial Int...  \n",
       "9997                     , Statistics, Machine Learning  \n",
       "9998                , Physics, Astrophysics of Galaxies  \n",
       "9999  , Physics, Materials Science, Strongly Correla...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ABSTRACT\"]=df.ABSTRACT.apply(round2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x46559 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 684410 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(df.ABSTRACT)\n",
    "data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "# import  nltk\n",
    "# def tokenize_text(text):\n",
    "#     tokens = nltk.word_tokenize(text)\n",
    "#     return ' '.join(tokens) \n",
    "\n",
    "# df['ABSTRACT']=df['ABSTRACT'].apply(tokenize_text)\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  nltk\n",
    "ps=nltk.PorterStemmer()\n",
    "df[\"ABSTRACT\"]=df[\"ABSTRACT\"].apply(lambda content: ' '.join([ps.stem(word) for word in content.split(' ')]))\n",
    "# df[\"ABSTRACT\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a backpressur algorithm ha been wide use as th...</td>\n",
       "      <td>[ Computer Science,  Mathematics,  Optimizatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insid thi paper we present an exactli solvabl ...</td>\n",
       "      <td>[ Physics,  Strongly Correlated Electrons]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a present numer studi aim at shed light on a m...</td>\n",
       "      <td>[ Physics,  Fluid Dynamics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with the help of angleresolv photoemiss spectr...</td>\n",
       "      <td>[ Physics,  Strongly Correlated Electrons,  Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base on subarcsecond atacama larg millimetersu...</td>\n",
       "      <td>[ Physics,  Astrophysics of Galaxies]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ABSTRACT  \\\n",
       "0  a backpressur algorithm ha been wide use as th...   \n",
       "1  insid thi paper we present an exactli solvabl ...   \n",
       "2  a present numer studi aim at shed light on a m...   \n",
       "3  with the help of angleresolv photoemiss spectr...   \n",
       "4  base on subarcsecond atacama larg millimetersu...   \n",
       "\n",
       "                                            category  \n",
       "0  [ Computer Science,  Mathematics,  Optimizatio...  \n",
       "1         [ Physics,  Strongly Correlated Electrons]  \n",
       "2                        [ Physics,  Fluid Dynamics]  \n",
       "3  [ Physics,  Strongly Correlated Electrons,  Su...  \n",
       "4              [ Physics,  Astrophysics of Galaxies]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# #hot encoding\n",
    "df['category']=df['category'].apply(lambda s : s.split(',')[1:])\n",
    "# one_hot_encoded = pd.get_dummies(df['category'].apply(pd.Series).stack()).sum(level=0)\n",
    "# df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "# df.drop(\"category\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x=df[\"ABSTRACT\"]\n",
    "y=df['category']\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Create an instance of the MultiLabelBinarizer transformer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit the transformer on the target variable y_train\n",
    "mlb.fit(y_train)\n",
    "\n",
    "# Transform y_train and y_test to binary arrays\n",
    "y_train_bin = mlb.transform(y_train)\n",
    "y_test_bin = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "250/250 [==============================] - 23s 70ms/step - loss: 0.2883 - accuracy: 0.2042\n",
      "Epoch 2/8\n",
      "250/250 [==============================] - 19s 77ms/step - loss: 0.2523 - accuracy: 0.2499\n",
      "Epoch 3/8\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.2148 - accuracy: 0.3134\n",
      "Epoch 4/8\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.1902 - accuracy: 0.3593\n",
      "Epoch 5/8\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.1723 - accuracy: 0.3751\n",
      "Epoch 6/8\n",
      "250/250 [==============================] - 18s 73ms/step - loss: 0.1602 - accuracy: 0.3636\n",
      "Epoch 7/8\n",
      "250/250 [==============================] - 19s 77ms/step - loss: 0.1499 - accuracy: 0.3632\n",
      "Epoch 8/8\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.1386 - accuracy: 0.3591\n",
      "63/63 [==============================] - 4s 35ms/step\n",
      "Accuracy: 0.0555\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM, SimpleRNN, Embedding, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_tokenized = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokenized = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_padded = pad_sequences(X_train_tokenized, maxlen=100)\n",
    "X_test_padded = pad_sequences(X_test_tokenized, maxlen=100)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=32))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(categories), activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_padded, y_train_bin, epochs=8, batch_size=32)\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test_bin)\n",
    "print(f'Test loss: {loss}, test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\salma\\Downloads\\dataquest-challenge-2\\trah.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/salma/Downloads/dataquest-challenge-2/trah.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test=pd.read_csv(\"test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create an instance of the TfidfVectorizer transformer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit the transformer on the input data\n",
    "bow = tfidf.fit_transform(X_train)\n",
    "bow_test = tfidf.transform(X_test)\n",
    "bow_sparse = csr_matrix(bow)\n",
    "bow_tensor = tf.sparse.SparseTensor(\n",
    "    indices=bow_sparse.nonzero(),\n",
    "    values=bow_sparse.data,\n",
    "    dense_shape=bow_sparse.shape\n",
    ")\n",
    "bow_tensor = tf.sparse.reorder(bow_tensor)\n",
    "\n",
    "# Create an instance of the MultiLabelBinarizer transformer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit the transformer on the target variable y_train\n",
    "mlb.fit(y_train)\n",
    "\n",
    "# Transform y_train and y_test to binary arrays\n",
    "y_train_bin = mlb.transform(y_train)\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train_bin)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=bow.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(categories), activation='sigmoid'))\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(bow_sparse, y_train_tensor, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(bow_test)\n",
    "\n",
    "# Convert the predictions to multi-hot encoded format\n",
    "y_pred_bin = (y_pred > 0.5).astype(int)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yalla tarf eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "x=df[\"ABSTRACT\"]\n",
    "y=df['category']\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "tfidf = TfidfVectorizer()\n",
    "bow2=tfidf.fit_transform(X_train)\n",
    "bow2_test=tfidf.transform(X_test)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Create an instance of the MultiLabelBinarizer transformer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit the transformer on the target variable y_train\n",
    "mlb.fit(y_train)\n",
    "\n",
    "# Transform y_train and y_test to binary arrays\n",
    "\n",
    "\n",
    "y_train_bin = mlb.transform(y_train)\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "# Sort the indices of the sparse matrix\n",
    "bow2_sparse = tf.sparse.SparseTensor(\n",
    "    indices=bow2.nonzero(),\n",
    "    values=bow2.data,\n",
    "    dense_shape=bow2.shape\n",
    ")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=bow2.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train_bin.shape[1], activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(bow2_sparse, y_train_bin, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(bow2_test)\n",
    "\n",
    "\n",
    "# Convert the predictions to one-hot encoded format\n",
    "y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test_bin, y_pred_bin)\n",
    "print('Accuracy: %.2f%%' % (accuracy * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "x=df[\"ABSTRACT\"]\n",
    "# y=df['category'].apply(lambda s: s.split(',')[1:])\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Create an instance of the MultiLabelBinarizer transformer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit the transformer on the target variable y_train\n",
    "mlb.fit(y_train)\n",
    "# print(y)\n",
    "# Transform y_train and y_test to binary arrays\n",
    "\n",
    "\n",
    "y_train_bin = mlb.transform(y_train)\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "# y_train_bin = y_train_bin.flatten()\n",
    "# y_test_bin = y_test_bin.flatten()\n",
    "\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# # Define the model architecture\n",
    "# model = Sequential()\n",
    "# model.add(Dense(512, activation='relu', input_dim=bow2.shape[1]))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(y_train_bin.shape[1], activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# model.fit(bow2, y_train_bin, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# loss, accuracy = model.evaluate(bow2_test, y_test_bin, batch_size=32)\n",
    "# print('Test accuracy:', accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tfidf = TfidfVectorizer()\n",
    "# X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "# clf = LogisticRegression()\n",
    "# y_test_bin\n",
    "\n",
    "# clf.fit(X_train_tfidf, y_train_bin)\n",
    "# X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# # Use the trained model to make predictions on the test data\n",
    "# y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# # Evaluate the performance of the model on the test data\n",
    "# accuracy = accuracy_score(y_test_bin, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# cv = CountVectorizer()\n",
    "# bow1=cv.fit_transform(X_train)\n",
    "# bow1_test=cv.transform(X_test)\n",
    "# tfidf = TfidfVectorizer()\n",
    "# bow2=tfidf.fit_transform(X_train)\n",
    "# bow2_test=tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.svm import SVC\n",
    "# tfidf = TfidfVectorizer()\n",
    "# bow=tfidf.fit_transform(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
